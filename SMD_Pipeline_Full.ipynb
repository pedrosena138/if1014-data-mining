{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrosena138/if1014-data-mining/blob/main/SMD_Pipeline_Full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmV2E6IaenPY",
        "outputId": "7441440c-d294-4bc5-8274-760afbed3149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compare Algorithms script\n",
        "\n",
        "#1. Definicao das bibliotecas\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "#2. Definicao da semente para geracao de numereos aleatorios\n",
        "#Intialise a random number generator\n",
        "# Set a seed value\n",
        "seed_value= 12321 \n",
        "# 1. Set 'PYTHONHASHSEED' environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "# 2. Set 'python' built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "#3. Leitura dos dados\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pandas.read_csv(\"pima-indians-diabetes.csv\", names=names)\n",
        "\n",
        "#4. A analise exploratoria dos dados realizada em outro script\n",
        "\n",
        "#5. Preparacao dos dados conduzida em outro script\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataframe.shape)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "#6. Divisao da base de dados em treinamento, validacao e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=seed_value)\n",
        "\n",
        "#X_train_p, X_valid, y_train_p, y_valid = train_test_split(X_train, y_train, random_state=seed)\n",
        "\n",
        "#7. Realizar busca com o gridsearch ou randonsearhc para encontrar os melhores parametros de cada modelo\n",
        "# define models\n",
        "decisionTree = DecisionTreeClassifier()\n",
        "svc = SVC()\n",
        "\n",
        "# define evaluation\n",
        "cv = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# define search space for decision tree\n",
        "space = dict()\n",
        "space['criterion'] = ['gini', 'entropy']\n",
        "space['min_samples_split'] = [2,3,5,7]\n",
        "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
        "space['min_samples_leaf'] = [2, 3]\n",
        "\n",
        "# defining parameter range for svm\n",
        "param_grid = {'C': [0.1, 1, 10,],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['rbf']}\n",
        "\n",
        "# define random search for decision tree\n",
        "search = RandomizedSearchCV(decisionTree, space, n_iter=50, scoring='accuracy', n_jobs=4, cv=cv)\n",
        "\n",
        "# execute search\n",
        "result_tree = search.fit(X_train, y_train)\n",
        "\n",
        "# summarize result for decision tree\n",
        "print('=========Random Search Results fro TREE==========')\n",
        "print('Best Score: %s' % result_tree.best_score_)\n",
        "print('Best Hyperparameters: %s' % result_tree.best_params_)\n",
        "\n",
        "# define random search for SVM\n",
        "search = RandomizedSearchCV(svc, param_grid, n_iter=10, scoring='accuracy', n_jobs=4, cv=cv, random_state=seed_value)\n",
        "\n",
        "# execute search\n",
        "result_svc = search.fit(X_train, y_train)\n",
        "\n",
        "# summarize result for SVM\n",
        "print('=========Random Search Results for SVM==========')\n",
        "print('Best Score: %s' % result_svc.best_score_)\n",
        "print('Best Hyperparameters: %s' % result_svc.best_params_)\n",
        "\n",
        "\n",
        "#8. Definicao dos modelos de classificacao com as melhores configuracoes\n",
        "# criacao dos modelos com os melhores parametros\n",
        "RFC = RandomForestClassifier(n_estimators=10,random_state=seed_value)\n",
        "svc = result_svc.best_estimator_\n",
        "DTC = result_tree.best_estimator_   #tree.DecisionTreeClassifier(criterion='entropy', random_state=seed)\n",
        "MLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,5), random_state=seed_value)\n",
        "BMLP = BaggingClassifier(base_estimator=MLP, n_estimators=10, random_state=seed_value)\n",
        "\n",
        "#adiciona os modelos em uma lista\n",
        "models = []\n",
        "models.append(('Arvore', DTC))\n",
        "models.append(('SVM', svc))\n",
        "models.append(('ComiteArvore', RFC))\n",
        "models.append(('RedeNeural', MLP))\n",
        "models.append(('ComiteRede', BMLP))\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "#deficao da metrica a ser utilizada\n",
        "scoring = 'accuracy'\n",
        "\n",
        "#9. Definicao do modelo experimental\n",
        "#amostragem estratificada\n",
        "#kfold = cv\n",
        "\n",
        "#10 Execucao do modelo experimental\n",
        "#avaliacao de cada modelo nas amotragens estratificas\n",
        "print('\\nDesempenhos medios dos modelos:')\n",
        "for name, model in models:\n",
        "\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=10, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "\n",
        "#11 Comparacao de modelos\n",
        "# Teste de hipotese analisando o p-value\n",
        "stat, p = stats.kruskal(results[0],results[1],results[2],results[3],results[4])\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('\\nSame distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('\\nDifferent distributions (reject H0)')\n",
        " \n",
        "print('\\nComparison stats', stat)\n",
        "\n",
        "print('Comparacao Arvore | SVM ->', stats.kruskal(results[0],results[1]))\n",
        "print('Comparacao Arvore | ComiteArvore ->', stats.kruskal(results[0],results[2]))\n",
        "print('Comparacao Arvore | RedeNeural ->',stats.kruskal(results[0],results[3]))\n",
        "print('Comparacao Arvore | CRNA ->',stats.kruskal(results[0],results[4]))\n",
        "print('Comparacao SVM | RedeNeural ->',stats.kruskal(results[2],results[3]))\n",
        "print('Comparacao SVM | ComiteRede ->',stats.kruskal(results[2],results[4]))\n",
        "print('Comparacao RedeNeural | ComiteRede ->',stats.kruskal(results[3],results[4]))\t\n",
        "\n",
        "#treinamento dos modelos no conjunto de treino completo (sem divisao de validacao)\n",
        "RFC.fit(X_train, y_train);\n",
        "svc.fit(X_train, y_train);\n",
        "DTC.fit(X_train, y_train);\n",
        "MLP.fit(X_train, y_train);\n",
        "BMLP.fit(X_train, y_train);\n",
        "\n",
        "#predicao de cada modelo para a base de teste\n",
        "Y_test_prediction_RFC = RFC.predict(X_test)\n",
        "Y_test_prediction_SVC = svc.predict(X_test)\n",
        "Y_test_prediction_DTC = DTC.predict(X_test)\n",
        "Y_test_prediction_MLP = MLP.predict(X_test)\n",
        "Y_test_prediction_BMLP = BMLP.predict(X_test)\n",
        "\n",
        "#12 Apresentacao de resultados\n",
        "print(\"\\nAcuracia Comite de Arvore: Treinamento\",  RFC.score(X_train, y_train),\" Teste\" ,RFC.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_RFC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_RFC))\n",
        "\n",
        "print(\"\\nAcuracia SVC: Treinamento\",  svc.score(X_train, y_train),\" Teste\" ,svc.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_SVC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_SVC))\n",
        "\n",
        "print(\"\\nAcuracia Arvore: Treinamento\",  DTC.score(X_train, y_train),\" Teste\" ,DTC.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_DTC))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_DTC))\n",
        "\n",
        "print(\"\\nAcuracia Rede Neural: Treinamento\",  MLP.score(X_train, y_train),\" Teste\" ,MLP.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_MLP))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_MLP))\n",
        "\n",
        "print(\"\\nAcuracia Comite RNA: Treinamento\",  BMLP.score(X_train, y_train),\" Teste\" ,BMLP.score(X_test, y_test))\n",
        "print(\"Clasification report:\", classification_report(y_test, Y_test_prediction_BMLP))\n",
        "print(\"Confussion matrix:\\n\", confusion_matrix(y_test, Y_test_prediction_BMLP))\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\t\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apresentando o shape dos dados (dimenssoes)\n",
            "(768, 9)\n",
            "=========Random Search Results fro TREE==========\n",
            "Best Score: 0.7322444041137326\n",
            "Best Hyperparameters: {'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 9, 'criterion': 'entropy'}\n",
            "=========Random Search Results for SVM==========\n",
            "Best Score: 0.7186630369026014\n",
            "Best Hyperparameters: {'kernel': 'rbf', 'gamma': 0.001, 'C': 10}\n",
            "\n",
            "Desempenhos medios dos modelos:\n",
            "Arvore: 0.728857 (0.054322)\n",
            "SVM: 0.718663 (0.056128)\n",
            "ComiteArvore: 0.760557 (0.025305)\n",
            "RedeNeural: 0.666697 (0.016214)\n",
            "ComiteRede: 0.706776 (0.036279)\n",
            "\n",
            "Different distributions (reject H0)\n",
            "\n",
            "Comparison stats 17.441270300226485\n",
            "Comparacao Arvore | SVM -> KruskalResult(statistic=0.023030303030308678, pvalue=0.8793782968510974)\n",
            "Comparacao Arvore | ComiteArvore -> KruskalResult(statistic=2.0863878326996175, pvalue=0.14861710260361805)\n",
            "Comparacao Arvore | RedeNeural -> KruskalResult(statistic=5.927189642041126, pvalue=0.014909000274472346)\n",
            "Comparacao Arvore | CRNA -> KruskalResult(statistic=1.0477307110438696, pvalue=0.30603030393578284)\n",
            "Comparacao SVM | RedeNeural -> KruskalResult(statistic=14.470677837014462, pvalue=0.00014235838876487588)\n",
            "Comparacao SVM | ComiteRede -> KruskalResult(statistic=8.358263518659562, pvalue=0.0038393728949071035)\n",
            "Comparacao RedeNeural | ComiteRede -> KruskalResult(statistic=6.170253651037655, pvalue=0.012991598051358421)\n",
            "\n",
            "Acuracia Comite de Arvore: Treinamento 0.9913194444444444  Teste 0.6979166666666666\n",
            "Clasification report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.91      0.79       116\n",
            "         1.0       0.74      0.37      0.49        76\n",
            "\n",
            "    accuracy                           0.70       192\n",
            "   macro avg       0.71      0.64      0.64       192\n",
            "weighted avg       0.71      0.70      0.67       192\n",
            "\n",
            "Confussion matrix:\n",
            " [[106  10]\n",
            " [ 48  28]]\n",
            "\n",
            "Acuracia SVC: Treinamento 0.9322916666666666  Teste 0.6666666666666666\n",
            "Clasification report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.84      0.75       116\n",
            "         1.0       0.62      0.41      0.49        76\n",
            "\n",
            "    accuracy                           0.67       192\n",
            "   macro avg       0.65      0.62      0.62       192\n",
            "weighted avg       0.66      0.67      0.65       192\n",
            "\n",
            "Confussion matrix:\n",
            " [[97 19]\n",
            " [45 31]]\n",
            "\n",
            "Acuracia Arvore: Treinamento 0.9131944444444444  Teste 0.71875\n",
            "Clasification report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.84      0.78       116\n",
            "         1.0       0.69      0.53      0.60        76\n",
            "\n",
            "    accuracy                           0.72       192\n",
            "   macro avg       0.71      0.69      0.69       192\n",
            "weighted avg       0.71      0.72      0.71       192\n",
            "\n",
            "Confussion matrix:\n",
            " [[98 18]\n",
            " [36 40]]\n",
            "\n",
            "Acuracia Rede Neural: Treinamento 0.6666666666666666  Teste 0.6041666666666666\n",
            "Clasification report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      1.00      0.75       116\n",
            "         1.0       0.00      0.00      0.00        76\n",
            "\n",
            "    accuracy                           0.60       192\n",
            "   macro avg       0.30      0.50      0.38       192\n",
            "weighted avg       0.37      0.60      0.46       192\n",
            "\n",
            "Confussion matrix:\n",
            " [[116   0]\n",
            " [ 76   0]]\n",
            "\n",
            "Acuracia Comite RNA: Treinamento 0.7430555555555556  Teste 0.671875\n",
            "Clasification report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.96      0.78       116\n",
            "         1.0       0.78      0.24      0.36        76\n",
            "\n",
            "    accuracy                           0.67       192\n",
            "   macro avg       0.72      0.60      0.57       192\n",
            "weighted avg       0.71      0.67      0.61       192\n",
            "\n",
            "Confussion matrix:\n",
            " [[111   5]\n",
            " [ 58  18]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-zog1U9EwyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e188ce2-4dcc-4e7d-abf6-73c81719fb3d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=2)\n",
        "\n",
        "[cj_train, cj_test] = skf.split(X,Y)\n",
        "\n",
        "print(cj_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
            "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
            "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
            "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
            "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
            "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
            "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
            "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
            "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
            "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
            "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
            "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
            "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
            "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
            "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
            "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
            "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
            "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
            "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
            "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
            "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
            "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
            "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
            "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
            "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
            "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
            "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
            "       351, 352, 353, 354, 358, 361, 362, 364, 365, 367, 368, 371, 372,\n",
            "       373, 374, 376, 377, 379, 380, 381, 382, 383, 384, 385, 389, 390,\n",
            "       392, 393, 395, 396, 398, 401, 403]), array([355, 356, 357, 359, 360, 363, 366, 369, 370, 375, 378, 386, 387,\n",
            "       388, 391, 394, 397, 399, 400, 402, 404, 405, 406, 407, 408, 409,\n",
            "       410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422,\n",
            "       423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
            "       436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
            "       449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
            "       462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
            "       475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487,\n",
            "       488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500,\n",
            "       501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
            "       514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,\n",
            "       527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
            "       540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552,\n",
            "       553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
            "       566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,\n",
            "       579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591,\n",
            "       592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604,\n",
            "       605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617,\n",
            "       618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
            "       631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n",
            "       644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656,\n",
            "       657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669,\n",
            "       670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682,\n",
            "       683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695,\n",
            "       696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708,\n",
            "       709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721,\n",
            "       722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734,\n",
            "       735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747,\n",
            "       748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760,\n",
            "       761, 762, 763, 764, 765, 766, 767]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UWv5CGPhD_h",
        "outputId": "6b166650-86ac-4ffc-e468-e1d9b049f4e9"
      },
      "source": [
        "# Significance stats tests\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import mannwhitneyu\n",
        "from scipy.stats import friedmanchisquare\n",
        "from scipy.stats import kruskal\n",
        "from scipy.stats import wilcoxon\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate three independent samples\n",
        "data1 = 5 * randn(100) + 50\n",
        "data2 = 5 * randn(100) + 50\n",
        "data3 = 5 * randn(100) + 52\n",
        "\n",
        "# compare samples\n",
        "stat, p = mannwhitneyu(data1, data2)\n",
        "print('Mann-Whitney Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = wilcoxon(data1, data2)\n",
        "print('Wilcoxon Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = kruskal(data1, data2, data3)\n",
        "print('Kruskal-Wallis Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')\n",
        "\n",
        "stat, p = friedmanchisquare(data1, data2, data3)\n",
        "print('Friedman Statistic: s=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mann-Whitney Statistic: s=4597.000, p=0.163\n",
            "Same distributions (fail to reject H0)\n",
            "Wilcoxon Statistic: s=2314.000, p=0.468\n",
            "Same distributions (fail to reject H0)\n",
            "Kruskal-Wallis Statistic: s=0.970, p=0.325\n",
            "Same distributions (fail to reject H0)\n",
            "Friedman Statistic: s=9.360, p=0.009\n",
            "Different distributions (reject H0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21shpaFfTsv"
      },
      "source": [
        "# random search decision tree model on the pima-diabetes dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Leitura dos dados\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(\"pima-indians-diabetes.csv\", names=names)\n",
        "\n",
        "#Preparacao dos dados conduzida em outro script\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataframe.shape)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "y = array[:,8]\n",
        "\n",
        "# define model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# define search space\n",
        "space = dict()\n",
        "space['criterion'] = ['gini', 'entropy']\n",
        "space['min_samples_split'] = [2,3,5,7]\n",
        "space['max_depth'] = [3,5,6,7,9,11,13,15,17,19]\n",
        "space['min_samples_leaf'] = [2, 3]\n",
        "\n",
        "# define random search\n",
        "search = RandomizedSearchCV(model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "# summarize result\n",
        "print('=========Random Search Results==========')\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n",
        "# define grid search\n",
        "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "\n",
        "# execute search\n",
        "result = search.fit(X, y)\n",
        "\n",
        "print('=========Grid Search Results==========')\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI8dzY9yuM4G"
      },
      "source": [
        "print(result.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}