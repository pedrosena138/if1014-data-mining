{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrosena138/if1014-data-mining/blob/main/Pre_processamento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiG1TTPeNoWi"
      },
      "source": [
        "\n",
        "#Disciplina de Solucoes em Mineracao de dados\n",
        "#--------------------------------------------------------\n",
        "#Script para tratamentos de valores ausentes\n",
        "#--------------------------------------------------------\n",
        "\n",
        "\n",
        "# Importando as bibliotecas necessarias\n",
        "import pandas\n",
        "import scipy\n",
        "import numpy\n",
        "\n",
        "from pandas import read_csv\n",
        "\n",
        "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
        "\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataset.shape)\n",
        "\n",
        "print(\"Conhecendo os dados estatisticos dos dados carregados (describe)\")\n",
        "print(dataset.describe())\n",
        "\n",
        "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
        "\t\t\"os 10 primeiros registros (head(10))\")\n",
        "print(dataset.head(10))\n",
        "\n",
        "print(\"Quantidade de pontos que possue 0 como valor\")\n",
        "print((dataset[[1,2,3,4,5]] == 0).sum())\n",
        "\n",
        "# Marcar os valores ausentes como NaN = not a number\n",
        "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, numpy.NaN)\n",
        "\n",
        "print(\"Realiza a contagem de valores NaN em cada coluna\")\n",
        "print(dataset.isnull().sum())\n",
        "\n",
        "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
        "\t\t\"os 10 primeiros registros (head(10))\")\n",
        "print(dataset.head(10)) \n",
        "\n",
        "#Abordagems para substituicao do NaN\n",
        "#usando a media (mean) mediana (median) coluna por coluna\n",
        "dataset.fillna(dataset.median(), inplace=True)\n",
        "\n",
        "#preenchendo com as ocorrencias mais pr√≥ximas\n",
        "#dataset.fillna(method='ffill',inplace=True)\n",
        "\n",
        "# Removendo registros que possuem valores ausentes (NaN)\n",
        "#dataset.dropna(inplace=True)\n",
        "\n",
        "# Preenchendo os valores ausentes com base na media dos valores da coluna\n",
        "# existe ainda as opcoes via mediana e valores mais frequentes\n",
        "#dataset.fillna(dataset.mean(), inplace=True)\n",
        "\n",
        "#fazendo interpolacao para encontrar os novos valores para NaN\n",
        "#dataset=dataset.interpolate()\n",
        "\n",
        "print(\"Mostra a quantidade de valores ausentes (NaN) de cada coluna\")\n",
        "print(dataset.isnull().sum())\n",
        "print(dataset.shape)\n",
        "\n",
        "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
        "\t\t\"os 20 primeiros registros (head(20))\")\n",
        "print(dataset.head(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkFAkyGTbPro"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "#Realizando a remocao de valores aberrantes de atributos\n",
        "\n",
        "\n",
        "#Utilizando a base de dados com caracteristicas de carros\n",
        "dataset = pd.read_csv('/content/mtcars.csv')\n",
        "\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataset.shape)\n",
        "\n",
        "print(\"Conhecendo os dados estatisticos dos dados carregados (describe)\")\n",
        "print(dataset.describe())\n",
        "\n",
        "print('Apresentando os primeiros registros')\n",
        "print(dataset.head())\n",
        "\n",
        "# print('Quantidade de valores zeros')\n",
        "# print((dataset[['cyl','hp']] == 0).sum())\n",
        "\n",
        "#Gerando boxplot para a caracteristia HP\n",
        "sns.boxplot(data=dataset,x=dataset['hp'])\n",
        "\n",
        "#obtendo o valor do Q1\n",
        "Q1=dataset['hp'].quantile(0.25)\n",
        "\n",
        "#obtendo o valor do Q3\n",
        "Q3=dataset['hp'].quantile(0.75)\n",
        "\n",
        "#obtendo a faixa de valores interquartil\n",
        "IQR=Q3-Q1\n",
        "\n",
        "print(Q1)\n",
        "\n",
        "print(Q3)\n",
        "\n",
        "print(IQR)\n",
        "\n",
        "Lower_Whisker = Q1-1.5*IQR\n",
        "\n",
        "Upper_Whisker = Q3+1.5*IQR\n",
        "\n",
        "print(Lower_Whisker, Upper_Whisker)\n",
        "\n",
        "dataset = dataset[dataset['hp']< Upper_Whisker]\n",
        "\n",
        "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
        "print(dataset.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81e2ceXOijJ0",
        "outputId": "5b32f076-384d-45a1-ec4a-4fcd84d7316a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "#Realizando a discretizacao de atributos continuos\n",
        "#Create a DataFrame\n",
        "df1 = {\n",
        "    'Name':['George','Andrea','micheal','maggie','Ravi','Xien','Jalpa','Tyieren'],    \n",
        "    'Score':[63,48,56,75,32,77,85,22]\n",
        "     \n",
        "   }\n",
        " \n",
        " \n",
        "df1 = pd.DataFrame(df1,columns=['Name','Score'])\n",
        "print(df1)\n",
        "\n",
        "''' binning or bucketing with range'''\n",
        " \n",
        "bins = [0, 25, 50, 75, 100]\n",
        "df1['binned'] = pd.cut(df1['Score'], bins)\n",
        "print (df1)\n",
        "\n",
        "\n",
        "''' binning or bucketing with labels'''\n",
        " \n",
        "bins = [0, 25, 50, 75, 100]\n",
        "labels =[1,2,3,4]\n",
        "df1['binned'] = pd.cut(df1['Score'], bins,labels=labels)\n",
        "print (df1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name  Score\n",
            "0   George     63\n",
            "1   Andrea     48\n",
            "2  micheal     56\n",
            "3   maggie     75\n",
            "4     Ravi     32\n",
            "5     Xien     77\n",
            "6    Jalpa     85\n",
            "7  Tyieren     22\n",
            "      Name  Score     binned\n",
            "0   George     63   (50, 75]\n",
            "1   Andrea     48   (25, 50]\n",
            "2  micheal     56   (50, 75]\n",
            "3   maggie     75   (50, 75]\n",
            "4     Ravi     32   (25, 50]\n",
            "5     Xien     77  (75, 100]\n",
            "6    Jalpa     85  (75, 100]\n",
            "7  Tyieren     22    (0, 25]\n",
            "      Name  Score binned\n",
            "0   George     63      3\n",
            "1   Andrea     48      2\n",
            "2  micheal     56      3\n",
            "3   maggie     75      3\n",
            "4     Ravi     32      2\n",
            "5     Xien     77      4\n",
            "6    Jalpa     85      4\n",
            "7  Tyieren     22      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2szFGQPMlA1g"
      },
      "source": [
        "#--------------------------------------------------------\n",
        "#Script que padroniza os dados para media 0 e desvio 1\n",
        "#--------------------------------------------------------\n",
        "\n",
        "\n",
        "# Importando as bibliotecas necessarias\n",
        "import pandas\n",
        "import numpy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#definindo os nomes de cada coluna\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n",
        "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
        "\n",
        "print(\"Dados originais\")\n",
        "print(dataframe.head(5))\n",
        "\n",
        "#separa os dados de entrada e saida\n",
        "array = dataframe.values\n",
        "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
        "Y = array[:,8] #separa os dados da ultima coluna\n",
        "\n",
        "#padroniza os dados com media 0 e desvio 1\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "\n",
        "print(\"Resumo dos dados modificados\")\n",
        "numpy.set_printoptions(precision=3)\n",
        "print(rescaledX[0:5,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un_Lwa9MlTYV"
      },
      "source": [
        "#Disciplina de Solucoes em Mineracao de dados\n",
        "#--------------------------------------------------------\n",
        "#Script para normalizacao dos dados\n",
        "#--------------------------------------------------------\n",
        "\n",
        "\n",
        "# Importando as bibliotecas necessarias\n",
        "import pandas\n",
        "import numpy\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "#definindo os nomes de cada coluna\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n",
        "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
        "\n",
        "print(\"Dados originais\")\n",
        "print(dataframe.head(5))\n",
        "\n",
        "#separa os dados de entrada e saida\n",
        "array = dataframe.values\n",
        "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
        "Y = array[:,8] #separa os dados da ultima coluna\n",
        "\n",
        "#normaliza os dados\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "\n",
        "print(\"Resumo dos dados modificados\")\n",
        "numpy.set_printoptions(precision=3)\n",
        "print(normalizedX[0:5,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6KSAn0Plf67"
      },
      "source": [
        "#Disciplina de Solucoes em Mineracao de dados\n",
        "#--------------------------------------------------------\n",
        "#Script para a binarizacao de dados\n",
        "#--------------------------------------------------------\n",
        "\n",
        "\n",
        "# Importando as bibliotecas necessarias\n",
        "import pandas\n",
        "import numpy\n",
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "#definindo os nomes de cada coluna\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n",
        "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
        "\n",
        "print(\"Dados originais\")\n",
        "print(dataframe.head(5))\n",
        "\n",
        "#separa os dados de entrada e saida\n",
        "array = dataframe.values\n",
        "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
        "Y = array[:,8] #separa os dados da ultima coluna\n",
        "\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "\n",
        "print(\"Resumo dos dados modificados\")\n",
        "numpy.set_printoptions(precision=3)\n",
        "print(binaryX[0:5,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKjvkbW0liih"
      },
      "source": [
        "#Disciplina de Solucoes em Mineracao de dados\n",
        "#--------------------------------------------------------\n",
        "#Script para re-escala de dados\n",
        "#--------------------------------------------------------\n",
        "\n",
        "\n",
        "# Importando as bibliotecas necessarias\n",
        "import pandas\n",
        "import scipy\n",
        "import numpy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas import read_csv\n",
        "\n",
        "\n",
        "#definindo os nomes de cada coluna\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning\n",
        "dataframe = read_csv('pima-indians-diabetes.csv', names=names)\n",
        "\n",
        "print(\"Dados originais\")\n",
        "print(dataframe.head(5))\n",
        "\n",
        "#separa os dados de entrada e saida\n",
        "array = dataframe.values\n",
        "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
        "Y = array[:,8] #separa os dados da ultima coluna\n",
        "\n",
        "#realiza a re-escala dos dados\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataframe[['preg', 'plas']] = scaler.fit_transform(dataframe[['preg', 'plas']])\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Resumo dos dados modificadoss\")\n",
        "numpy.set_printoptions(precision=3)\n",
        "print(rescaledX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohG9SMyiuom-"
      },
      "source": [
        "#Universidade de Pernambuco (UPE)\n",
        "#Escola Politecnica de Pernambuco (Poli)\n",
        "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
        "#Disciplina de Solucoes em Mineracao de dados\n",
        "#--------------------------------------------------------\n",
        "#Script para converter dados categoricos em binarios\n",
        "#--------------------------------------------------------\n",
        "\n",
        "\n",
        "# Importando as bibliotecas necessarias\n",
        "import pandas\n",
        "import numpy\n",
        "\n",
        "# Define the headers since the data does not have any\n",
        "nomes = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
        "           \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
        "           \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
        "           \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
        "           \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "# Read in the CSV file and convert \"?\" to NaN\n",
        "df = pandas.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data',\n",
        "                  header=None, names=nomes, na_values=\"?\" )\n",
        "\n",
        "print(\"Dados originais\")\n",
        "print(df.head())\n",
        "\n",
        "print(df.dtypes) \n",
        "\n",
        "print(\"selecionar apenas as colunas que sao do tipo objeto/categorigos\")\n",
        "obj_df = df.select_dtypes(include=['object']).copy()\n",
        "print(obj_df.head())\n",
        "\n",
        "print(\"verificar a existencia de dados ausentes\")\n",
        "print(obj_df[obj_df.isnull().any(axis=1)])\n",
        "\n",
        "print(\"realiza a contagem de dados de um atributo\")\n",
        "print(obj_df[\"num_doors\"].value_counts())\n",
        "\n",
        "print(\"realiza o preenchimento NaN com um valor especifico\")\n",
        "obj_df = obj_df.fillna({\"num_doors\": \"four\"})\n",
        "\n",
        "#conversao de categorigo para binario\n",
        "print(pandas.get_dummies(obj_df, columns=[\"drive_wheels\"]).head())\n",
        "\n",
        "dfb = pandas.get_dummies(obj_df, columns=[\"drive_wheels\"]);\n",
        "\n",
        "print(pandas.get_dummies(dfb, columns=[\"body_style\"]).head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UdQBGJDTt95"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn import tree\n",
        "\n",
        "# Load iris\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Constroi um classificador com arvore de decisao\n",
        "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
        "dt.fit(X, y)\n",
        "dotfile = open(\"dt-iris.dot\", 'w')\n",
        "tree.export_graphviz(dt, out_file=dotfile, feature_names=iris.feature_names)\n",
        "dotfile.close()\n",
        "print(\"Arvore de decisao gerada no diretorio!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}